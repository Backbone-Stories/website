# Screaming into the Void of the Internet
## What Orwell Got Wrong
Kirby Ferguson's post "Censored For 48 Hours" about the brief removal of one of his videos for "cyberbullying" has sparked some thoughts about ways to improve the content review process. I want to expand on several of his suggestions, about transparency and censorship, but you should start with his post first if you haven't yet.

Kirby's insight that by censoring material it can cause the inverse intention - the [Streisand effect](https://en.wikipedia.org/wiki/Streisand_effect) - where more attention comes from being banned. This to me points towards the path forward. Attention is the rare resource here. Perception matters and as Kirby points out being banned can radicalize people with views in the gray zone. Platforms are failing at an impossible mission by trying to play the outright guardian of truth for all users. These companies should flip the script by giving all users the power to opt-in or opt-out of filtering efforts. You want to read the sitting President's tweets, no matter how false they are deemed to be by the platform, then opt _out_ of warning labels on his tweets. Make the process available but full of friction so that the default choice is what 95%+ of users experience content with additional context to fight disinformation. This step alone removes the rhetorical attack of people screaming "censorship" by side stepping the volley. 

Orwell famously raised the dystopian nightmare of censorship in 1984. Big brother. Thought crimes. The nuenced discussion (covered by many smarter folks) that when YouTube, Facebook, or Twitter remove "free speech" from their platforms it's not the govenment that's censoring speech but a private company that's hosting it. The truth is complex but these nuances miss the simplistic attack that rings true enough to most Americans. Having something you've written deemed "too much" for these sites _feels_ Orwellian. Some now wear it as a badge of honor. I have a greater fear of the vapid mental intake of most social media than platforms where political debates become too crass. Huxley's view of a world where we entertain ourselves into oblivian rings truer to me than Orwell's direct assault on truth.

What is more dangerous for an idea: that it dies in obsurity (as most of our thoughts and works do) or that they're are deemed too dangerous (and gain the allure of the metaphorical apple from the tree of good and evil)?If you've ever tried to get attention online (for good or bad) you know that being ignored is far harsher than someone taking the time to disagree or even attack you. In many cases on the internet, and one of Trump's greatest strengths, is truly that no news is bad news. 

If a video strays too far from YouTube's guidelines, the gradient of actions only should only reach outright remove after: 
1. Demonitizing it (remove the economic incentive to dance along the line of the gray zone)
2. Deprioritizing it in the recommendation system (how the majority of videos gain viral reach)
3. Disabling comments (reduce engagement and the chance for even worse content to be highlighted by bad actors)
4. Deprioritizing it in search (Google already does this for web results)
5. Delist so it's only available via direct link

Maybe some of these actions already happen? Kirby's request for more transparency holds here. A community review board and other ways to determine why your views might be supressed are valid. The key here is that supression on the platform is not the same as censorship. Is this the perfect answer? No. And no system will be. I think the danger of the current approach from Twitter and Facebook in particular is that Congress will potentially introduce oversight which could be far more complex and less effective (potentially, I know smart folks are debating options). And the other clear outcome is that users are leaving for far more dangerous platforms where oversight might not even reach - Parlor, 8chan, and dark corners of Reddit for example (how on earth has the management of Reddit avoided being hauled before congress?).

There is a key distinction between stopping the spread of misinformation and trying to stop the _existence_ of misinformation. Information, however bad or dangerous it might be, will find a way to replicate and exist on the internet as long as data is basically free to copy and store. This site now is hosted for free on Github and could be de-platformed but I can take my markdown files to basically any other host and continue. At worst my git repo (nerd speak for backups) that stores all the files is copied to several of my machines. De-platforming me for instance would do almost nothing to stop this idea from existing other than maybe making it annoying for me to share it (which can be effective for low propensity bullshitters!) and could help the moderators at Github / Microsoft feel a little better.

Social media is terrible but some form of it will be with us for a long time. Leave terrible ideas to exist and scream into the dark empty void of internet space. Don't give fuel to bad ideas by giving them the allure of being dangerous. Use censorship as only the last resort. Reduce the attacks against platforms by giving users a burdensome process to opt-out. 